### model
model_name_or_path: Qwen/Qwen2.5-VL-3B-Instruct

# TỐI ƯU TỐC ĐỘ: Giảm image_max_pixels để tăng tốc độ xử lý (vẫn đủ chất lượng)
image_max_pixels: 32768  # Giảm từ 65536 để tăng tốc độ, vẫn đủ để nhận diện công thức toán
video_max_pixels: 16384
trust_remote_code: true
# Tối ưu memory khi load model
low_cpu_mem_usage: true

### method
stage: sft
do_train: true
# Sử dụng LoRA thay vì full fine-tuning để tiết kiệm memory
finetuning_type: lora
# LoRA settings - TỐI ƯU: Giảm rank để tăng tốc độ nhưng vẫn giữ chất lượng
lora_target: all  # Train trên tất cả các layer có thể
lora_rank: 8  # Giảm từ 16 xuống 8 để tăng tốc độ (giảm ~50% tham số train)
lora_alpha: 16  # Scaling factor = 2 * rank (giảm từ 32 xuống 16)
lora_dropout: 0.05  # Dropout để tránh overfitting
# Quantization 4-bit để giảm memory khi load model (QUAN TRỌNG cho GPU 8GB!)
quantization_bit: 4
quantization_method: bnb
double_quantization: true  # Tiết kiệm thêm memory
# Không cần freeze với LoRA vì chỉ train adapter
freeze_vision_tower: false
freeze_multi_modal_projector: false
freeze_language_model: false
# Bật HMER accuracy để hiển thị Exact Match Rate trong terminal
compute_hmer_accuracy: true  # Hiển thị accuracy (Exact Match Rate) trực tiếp trong logs
# Tắt deepspeed cho local training với RTX 3070 (8GB VRAM)
# deepspeed: examples/deepspeed/ds_z2_config.json

### dataset
# Bạn cần giải nén đầy đủ thư mục data/ trước khi sử dụng.
dataset_dir: ../../data
media_dir: ..
# CHỈ TRAIN VỚI CROHME để so sánh với bài báo
# CROHME bao gồm: 2014 (986 samples), 2016 (1147 samples), 2019 (1199 samples)
# Tổng cộng: ~3332 samples
dataset: crohme_2014, crohme_2016, crohme_2019

template: qwen2_vl
cutoff_len: 1024  # Giảm từ 2048 xuống 1024 để tăng tốc độ (LaTeX công thức thường ngắn)
max_samples: 20000000
overwrite_cache: true
# TỐI ƯU: Giảm workers để giảm overhead và tăng tốc độ
preprocessing_num_workers: 2  # Giảm từ 4 xuống 2
dataloader_num_workers: 1  # Giảm từ 2 xuống 1

### output
output_dir: saves/qwen2.5_vl-3b/lora/sft/standred/uni-mumer_crohme_local
logging_steps: 10
# Lưu checkpoint sau mỗi epoch để có thể so sánh kết quả
save_strategy: epoch  # Lưu sau mỗi epoch (thay vì steps)
save_steps: null  # Không dùng khi save_strategy = epoch
plot_loss: true
overwrite_output_dir: true
report_to: tensorboard
# Lưu kết quả evaluation vào file JSON
load_best_model_at_end: false  # Không load best model, giữ tất cả checkpoints
metric_for_best_model: eval_loss  # Metric để chọn best model (nếu dùng load_best_model_at_end)

### train
# LOCAL RTX 3070 (8GB): Tối ưu memory, có thể tăng batch size nếu còn VRAM
# TỐI ƯU: Tăng batch size lên 2 (với quantization 4-bit có thể làm được)
# Giảm gradient accumulation để tăng tốc độ
per_device_train_batch_size: 2  # Tăng từ 1 lên 2 (với quantization vẫn an toàn)
gradient_accumulation_steps: 8  # Giảm từ 16 xuống 8 (effective batch = 2 * 8 = 16, vẫn giữ chất lượng)
# Bật gradient checkpointing để tiết kiệm memory
gradient_checkpointing: true

# LoRA thường dùng learning rate cao hơn full fine-tuning
learning_rate: 5.0e-4  # Giữ nguyên cho LoRA
# LOCAL: Train vài epoch để test chất lượng và khả năng học của mô hình
# Với 3332 samples, batch_size=2, grad_accum=8: ~208 steps/epoch
# 5 epochs = 1,040 steps → khoảng 30-60 phút (đủ để test)
num_train_epochs: 5.0  # Tăng từ 2 lên 5 để test tốt hơn
lr_scheduler_type: cosine
warmup_ratio: 0.1
bf16: true
ddp_timeout: 180000000
save_only_model: true
resume_from_checkpoint: null
# Tối ưu memory
max_grad_norm: 1.0
optim: adamw_torch

### eval
# Bật evaluation để theo dõi accuracy và chất lượng mô hình
do_eval: true
# Tách 10% training data làm validation set
val_size: 0.1  # 10% của training data (~333 samples)
# Hoặc có thể dùng eval_dataset riêng nếu có
# eval_dataset: crohme_2014,crohme_2016,crohme_2019
per_device_eval_batch_size: 4  # Batch size cho evaluation (có thể lớn hơn train)
# Đánh giá sau mỗi epoch để lưu kết quả và so sánh
eval_strategy: epoch  # Đánh giá sau mỗi epoch (thay vì steps)
eval_steps: null  # Không dùng khi eval_strategy = epoch
# Metric: eval_loss, eval_perplexity sẽ được lưu trong mỗi checkpoint
# Kết quả được lưu tại: output_dir/trainer_state.json và mỗi checkpoint/eval_results.json

