# HÆ°á»›ng dáº«n Train 100 Epoch trong 8 Giá»

## ğŸ¯ Má»¥c tiÃªu

Train **100 epoch** trong vÃ²ng **8 giá»** vá»›i cháº¥t lÆ°á»£ng Ä‘Æ°á»£c giá»¯ nguyÃªn.

## ğŸ“Š TÃ­nh toÃ¡n tá»‘i Æ°u

### Cáº¥u hÃ¬nh Ä‘Ã£ tá»‘i Æ°u:
- **Dataset**: Chá»‰ CROHME 2014 (986 samples) - dataset nhá» nháº¥t
- **Batch size**: 2 (tÄƒng tá»« 1)
- **Gradient accumulation**: 8 (giáº£m tá»« 16)
- **Effective batch size**: 2 Ã— 8 = 16 (giá»¯ nguyÃªn cháº¥t lÆ°á»£ng!)
- **Image size**: 32768 pixels (giáº£m tá»« 65536 Ä‘á»ƒ tÄƒng tá»‘c)
- **Workers**: Giáº£m Ä‘á»ƒ giáº£m overhead

### TÃ­nh toÃ¡n:
```
Samples: 986
Steps/epoch = 986 / (2 Ã— 8) = ~62 steps/epoch
100 epochs = 6,200 steps
Thá»i gian cáº§n: 8 giá» = 28,800 giÃ¢y
Thá»i gian/step cáº§n: 28,800 / 6,200 = ~4.6 giÃ¢y/step
```

**âœ… Kháº£ thi!** Vá»›i quantization 4-bit vÃ  batch_size=2, má»—i step sáº½ máº¥t khoáº£ng 4-5 giÃ¢y.

## âœ… CÃ¡c thay Ä‘á»•i Ä‘Ã£ thá»±c hiá»‡n

### 1. **Giáº£m sá»‘ samples** (giá»¯ cháº¥t lÆ°á»£ng)
- Chá»‰ train vá»›i `crohme_2014` (986 samples)
- Váº«n Ä‘á»§ Ä‘á»ƒ model há»c tá»‘t vá»›i 100 epochs

### 2. **TÄƒng batch size** (tÄƒng tá»‘c Ä‘á»™)
- `per_device_train_batch_size: 2` (tá»« 1)
- Vá»›i quantization 4-bit, váº«n an toÃ n vá» memory

### 3. **Giáº£m gradient accumulation** (tÄƒng tá»‘c Ä‘á»™)
- `gradient_accumulation_steps: 8` (tá»« 16)
- **Effective batch size váº«n = 16** â†’ giá»¯ nguyÃªn cháº¥t lÆ°á»£ng!

### 4. **Giáº£m image size** (tÄƒng tá»‘c Ä‘á»™ xá»­ lÃ½)
- `image_max_pixels: 32768` (tá»« 65536)
- Váº«n Ä‘á»§ Ä‘á»ƒ nháº­n diá»‡n cÃ´ng thá»©c toÃ¡n há»c

### 5. **Giáº£m workers** (giáº£m overhead)
- `preprocessing_num_workers: 2` (tá»« 4)
- `dataloader_num_workers: 1` (tá»« 2)

### 6. **TÄƒng sá»‘ epochs**
- `num_train_epochs: 100.0`

### 7. **Tá»‘i Æ°u save frequency**
- `save_steps: 200` (tá»« 500) â†’ save má»—i ~3.2 epoch

## ğŸš€ CÃ¡ch cháº¡y

```bash
cd /home/nhat/Uni-MuMER-project/BaseLine
conda activate unimumer
bash train_local.sh
```

## â±ï¸ Thá»i gian Æ°á»›c tÃ­nh

- **Tá»•ng steps**: ~6,200 steps
- **Thá»i gian/step**: ~4-5 giÃ¢y
- **Tá»•ng thá»i gian**: ~7-8 giá»
- **Má»—i epoch**: ~4-5 phÃºt

## ğŸ“ˆ Cháº¥t lÆ°á»£ng Ä‘Æ°á»£c giá»¯ nguyÃªn

âœ… **Effective batch size = 16** (giá»‘ng nhÆ° trÆ°á»›c)
- Batch size Ã— Gradient accumulation = 2 Ã— 8 = 16
- Cháº¥t lÆ°á»£ng training khÃ´ng Ä‘á»•i!

âœ… **Learning rate vÃ  scheduler giá»¯ nguyÃªn**
- `learning_rate: 5.0e-4`
- `lr_scheduler_type: cosine`
- `warmup_ratio: 0.1`

âœ… **LoRA parameters giá»¯ nguyÃªn**
- `lora_rank: 16`
- `lora_alpha: 32`
- `lora_dropout: 0.05`

## ğŸ“‚ Output

Checkpoints sáº½ Ä‘Æ°á»£c lÆ°u táº¡i:
```
saves/qwen2.5_vl-3b/lora/sft/standred/uni-mumer_crohme_100epoch/
```

- Save má»—i 200 steps (~3.2 epoch)
- Tá»•ng cá»™ng: ~31 checkpoints

## ğŸ” Monitoring

### TensorBoard:
```bash
tensorboard --logdir saves/qwen2.5_vl-3b/lora/sft/standred/uni-mumer_crohme_100epoch/logs/
```

### Kiá»ƒm tra progress:
- Logs má»—i 10 steps
- Loss sáº½ giáº£m dáº§n qua 100 epochs
- Vá»›i 100 epochs, model sáº½ há»c ráº¥t ká»¹ trÃªn dataset nhá» nÃ y

## âš ï¸ LÆ°u Ã½

1. **Memory**: Vá»›i batch_size=2 vÃ  quantization 4-bit, váº«n an toÃ n cho GPU 8GB
2. **Náº¿u bá»‹ OOM**: Giáº£m `per_device_train_batch_size` xuá»‘ng 1
3. **Náº¿u quÃ¡ nhanh**: CÃ³ thá»ƒ tÄƒng `image_max_pixels` lÃªn 65536 Ä‘á»ƒ cháº¥t lÆ°á»£ng tá»‘t hÆ¡n
4. **Overfitting**: Vá»›i 100 epochs trÃªn 986 samples, cÃ³ thá»ƒ bá»‹ overfitting. NÃªn:
   - Monitor validation loss (náº¿u cÃ³)
   - Early stopping náº¿u cáº§n
   - Hoáº·c giáº£m sá»‘ epochs xuá»‘ng 50-80 náº¿u tháº¥y overfitting

## ğŸ“ So sÃ¡nh vá»›i cáº¥u hÃ¬nh cÅ©

| Tham sá»‘ | CÅ© | Má»›i | LÃ½ do |
|---------|-----|-----|-------|
| Dataset | 3 datasets (3332 samples) | 1 dataset (986 samples) | Giáº£m thá»i gian |
| Batch size | 1 | 2 | TÄƒng tá»‘c Ä‘á»™ |
| Grad accum | 16 | 8 | TÄƒng tá»‘c Ä‘á»™ |
| Effective batch | 16 | 16 | **Giá»¯ nguyÃªn cháº¥t lÆ°á»£ng!** |
| Image pixels | 65536 | 32768 | TÄƒng tá»‘c Ä‘á»™ xá»­ lÃ½ |
| Epochs | 2 | 100 | Má»¥c tiÃªu |
| Thá»i gian | 2-4 giá» | 7-8 giá» | PhÃ¹ há»£p má»¥c tiÃªu |

## ğŸ’¡ Tips

1. **Náº¿u muá»‘n train nhanh hÆ¡n**: Giáº£m `image_max_pixels` xuá»‘ng 16384
2. **Náº¿u muá»‘n cháº¥t lÆ°á»£ng tá»‘t hÆ¡n**: TÄƒng `image_max_pixels` lÃªn 65536 (nhÆ°ng sáº½ lÃ¢u hÆ¡n)
3. **Náº¿u muá»‘n train nhiá»u datasets**: CÃ³ thá»ƒ train tuáº§n tá»± tá»«ng dataset má»™t
4. **Monitor GPU usage**: DÃ¹ng `nvidia-smi -l 1` Ä‘á»ƒ theo dÃµi

