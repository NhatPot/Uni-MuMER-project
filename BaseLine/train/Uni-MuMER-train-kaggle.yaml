### model
model_name_or_path: Qwen/Qwen2.5-VL-3B-Instruct

# TỐI ƯU TỐC ĐỘ: Giảm image_max_pixels để tăng tốc độ xử lý (vẫn đủ chất lượng)
image_max_pixels: 32768  # Giảm từ 65536 để tăng tốc độ, vẫn đủ để nhận diện công thức toán
video_max_pixels: 16384
trust_remote_code: true
# Kaggle có nhiều RAM hơn, không cần low_cpu_mem_usage
low_cpu_mem_usage: false

### method
stage: sft
do_train: true
# Sử dụng LoRA thay vì full fine-tuning để tiết kiệm memory
finetuning_type: lora
# LoRA settings - TỐI ƯU: Giảm rank để tăng tốc độ nhưng vẫn giữ chất lượng
lora_target: all  # Train trên tất cả các layer có thể
lora_rank: 8  # Giảm từ 16 xuống 8 để tăng tốc độ (giảm ~50% tham số train)
lora_alpha: 16  # Scaling factor = 2 * rank (giảm từ 32 xuống 16)
lora_dropout: 0.05  # Dropout để tránh overfitting
# Kaggle T4 có 16GB VRAM, có thể không cần quantization hoặc dùng 8-bit
# Nhưng để an toàn và tăng tốc độ, vẫn dùng 4-bit
quantization_bit: 4
quantization_method: bnb
double_quantization: true  # Tiết kiệm thêm memory
# Không cần freeze với LoRA vì chỉ train adapter
freeze_vision_tower: false
freeze_multi_modal_projector: false
freeze_language_model: false
# Bật HMER accuracy để hiển thị Exact Match Rate trong terminal
compute_hmer_accuracy: true  # Hiển thị accuracy (Exact Match Rate) trực tiếp trong logs

### dataset
# Bạn cần giải nén đầy đủ thư mục data/ trước khi sử dụng.
dataset_dir: ../../data
media_dir: ..
# CHỈ TRAIN VỚI CROHME để so sánh với bài báo
# CROHME bao gồm: 2014 (986 samples), 2016 (1147 samples), 2019 (1199 samples)
# Tổng cộng: ~3332 samples
dataset: crohme_2014, crohme_2016, crohme_2019

template: qwen2_vl
cutoff_len: 1024  # Giảm từ 2048 xuống 1024 để tăng tốc độ (LaTeX công thức thường ngắn)
max_samples: 20000000
overwrite_cache: true
# TỐI ƯU: Giảm workers để giảm overhead và tăng tốc độ
preprocessing_num_workers: 2  # Giảm từ 4 xuống 2
dataloader_num_workers: 1  # Giảm từ 2 xuống 1

### output
output_dir: saves/qwen2.5_vl-3b/lora/sft/standred/uni-mumer_crohme_kaggle
logging_steps: 10
# Lưu checkpoint sau mỗi epoch để có thể so sánh kết quả
save_strategy: epoch  # Lưu sau mỗi epoch
save_steps: null  # Không dùng khi save_strategy = epoch
plot_loss: true
overwrite_output_dir: true
report_to: tensorboard
# Lưu kết quả evaluation vào file JSON
load_best_model_at_end: false  # Không load best model, giữ tất cả checkpoints
metric_for_best_model: eval_loss  # Metric để chọn best model

### train
# KAGGLE: 2 GPU T4 (16GB mỗi GPU) - có thể tăng batch size
# Với 2 GPU, batch size sẽ được nhân đôi tự động
per_device_train_batch_size: 4  # 4 per GPU × 2 GPU = 8 total
# Giảm gradient accumulation để tăng tốc độ
gradient_accumulation_steps: 4  # effective batch size = 4 * 2 * 4 = 32
# Bật gradient checkpointing để tiết kiệm memory
gradient_checkpointing: true

# LoRA thường dùng learning rate cao hơn full fine-tuning
learning_rate: 5.0e-4  # Giữ nguyên cho LoRA
# TỐI ƯU: Train 100 epoch trong 8 giờ
# Với 3332 samples, batch_size=4×2 GPU, grad_accum=4: ~104 steps/epoch
# 100 epochs = 10,400 steps → cần ~2.77 giây/step (khả thi với T4!)
num_train_epochs: 100.0
lr_scheduler_type: cosine
warmup_ratio: 0.1
bf16: true
ddp_timeout: 180000000
save_only_model: true
resume_from_checkpoint: null
# Tối ưu memory
max_grad_norm: 1.0
optim: adamw_torch

# Multi-GPU training
ddp_find_unused_parameters: false  # Tăng tốc độ DDP

### eval
# Bật evaluation để theo dõi accuracy và chất lượng mô hình
do_eval: true
# Tách 10% training data làm validation set
val_size: 0.1  # 10% của training data (~333 samples)
per_device_eval_batch_size: 8  # Batch size cho evaluation (có thể lớn hơn train)
# Đánh giá sau mỗi epoch để lưu kết quả và so sánh
eval_strategy: epoch  # Đánh giá sau mỗi epoch
eval_steps: null  # Không dùng khi eval_strategy = epoch
# Metric: eval_loss, eval_perplexity sẽ được lưu trong mỗi checkpoint
# Kết quả được lưu tại: output_dir/trainer_state.json và mỗi checkpoint/eval_results.json

