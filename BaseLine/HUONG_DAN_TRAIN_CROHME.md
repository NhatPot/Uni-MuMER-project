# HÆ°á»›ng dáº«n Train chá»‰ vá»›i Dataset CROHME

## ğŸ“Š ThÃ´ng tin Dataset

Báº¡n Ä‘ang train vá»›i **3 táº­p dá»¯ liá»‡u CROHME**:
- **CROHME 2014**: 986 samples
- **CROHME 2016**: 1147 samples  
- **CROHME 2019**: 1199 samples
- **Tá»•ng cá»™ng**: ~3,332 samples

## âœ… ÄÃ£ cáº¥u hÃ¬nh xong!

Config Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t trong `train/Uni-MuMER-train-local.yaml`:
- âœ… Chá»‰ train vá»›i `crohme_2014, crohme_2016, crohme_2019`
- âœ… Output directory: `saves/qwen2.5_vl-3b/lora/sft/standred/uni-mumer_crohme_only`
- âœ… Sá»­ dá»¥ng LoRA + Quantization 4-bit (tiáº¿t kiá»‡m memory)
- âœ… `num_train_epochs: 2.0` (cÃ³ thá»ƒ giáº£m xuá»‘ng 1.0 náº¿u muá»‘n train nhanh hÆ¡n)

## ğŸš€ CÃ¡ch cháº¡y

### BÆ°á»›c 1: Äáº£m báº£o mÃ´i trÆ°á»ng Ä‘Ã£ sáºµn sÃ ng
```bash
cd /home/nhat/Uni-MuMER-project/BaseLine
conda activate unimumer
```

### BÆ°á»›c 2: Cháº¡y training
```bash
bash train_local.sh
```

## â±ï¸ Thá»i gian train Æ°á»›c tÃ­nh

Vá»›i ~3,332 samples:
- **Batch size**: 1
- **Gradient accumulation**: 16 (effective batch = 16)
- **Epochs**: 2.0
- **Sá»‘ steps Æ°á»›c tÃ­nh**: ~416 steps/epoch Ã— 2 epochs = ~832 steps

**Thá»i gian Æ°á»›c tÃ­nh**: 
- Vá»›i RTX 3070 (8GB): Khoáº£ng **2-4 giá»** (tÃ¹y thuá»™c vÃ o tá»‘c Ä‘á»™ xá»­ lÃ½ áº£nh)

## ğŸ“ˆ So sÃ¡nh vá»›i bÃ i bÃ¡o

Sau khi train xong, báº¡n cÃ³ thá»ƒ:
1. **ÄÃ¡nh giÃ¡ model** trÃªn test set CROHME
2. **So sÃ¡nh metrics** vá»›i káº¿t quáº£ trong bÃ i bÃ¡o:
   - Mean Edit Score
   - BLEU-4 Score
   - Character Error Rate (CER)
   - Exact Match Rate

## ğŸ”§ TÃ¹y chá»‰nh nhanh (náº¿u muá»‘n train nhanh hÆ¡n Ä‘á»ƒ test)

Náº¿u muá»‘n train nhanh hÆ¡n Ä‘á»ƒ kiá»ƒm tra pipeline, cÃ³ thá»ƒ sá»­a trong `train/Uni-MuMER-train-local.yaml`:

```yaml
# Giáº£m sá»‘ epoch
num_train_epochs: 1.0  # Thay vÃ¬ 2.0

# Hoáº·c giá»›i háº¡n sá»‘ samples (chá»‰ train 1 dataset)
dataset: crohme_2014  # Chá»‰ train vá»›i 2014 (986 samples)
```

## ğŸ“‚ Output

Checkpoints sáº½ Ä‘Æ°á»£c lÆ°u táº¡i:
```
saves/qwen2.5_vl-3b/lora/sft/standred/uni-mumer_crohme_only/
```

Logs vÃ  TensorBoard:
- TensorBoard logs: `saves/qwen2.5_vl-3b/lora/sft/standred/uni-mumer_crohme_only/logs/`
- Xem TensorBoard: `tensorboard --logdir saves/qwen2.5_vl-3b/lora/sft/standred/uni-mumer_crohme_only/logs/`

## ğŸ“ LÆ°u Ã½

- Training sáº½ **nhanh hÆ¡n nhiá»u** so vá»›i train toÃ n bá»™ 13 datasets
- Káº¿t quáº£ sáº½ **phÃ¹ há»£p Ä‘á»ƒ so sÃ¡nh** vá»›i bÃ i bÃ¡o vÃ¬ chá»‰ train trÃªn CROHME
- Náº¿u muá»‘n train láº¡i vá»›i táº¥t cáº£ datasets, chá»‰ cáº§n sá»­a láº¡i `dataset:` trong config

